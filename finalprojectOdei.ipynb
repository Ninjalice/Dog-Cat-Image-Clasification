{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from scipy.signal import convolve\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearCeldas(image, N):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "  # Calculamos el número de bloques en filas y columnas\n",
    "    num_blocks_rows = height // N\n",
    "    num_blocks_cols = width // N\n",
    "\n",
    "    # Dividimos la imagen en bloques de 16 filas\n",
    "    blocks = np.vsplit(image, num_blocks_rows)\n",
    "\n",
    "    # Creamos una lista para guardar todas las celdas\n",
    "    celdas = []\n",
    "\n",
    "    # Iteramos sobre los bloques\n",
    "    for i, block in enumerate(blocks):\n",
    "        # Dividimos cada bloque en bloques d\n",
    "        # e 16 columnas\n",
    "        cells = np.hsplit(block, num_blocks_cols)\n",
    "\n",
    "        # Iteramos sobre las celdas\n",
    "        for j, cell in enumerate(cells):\n",
    "            # Añadimos cada celda a la lista\n",
    "            celdas.append(cell)\n",
    "\n",
    "    celdas = np.array(celdas)\n",
    "    return celdas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_to_col(imagen, m, n):\n",
    "    filas, columnas = imagen.shape\n",
    "    a = m//2\n",
    "    b = n//2\n",
    "    imagen2 = np.zeros((m*n, filas*columnas))\n",
    "    imagen_amp = cv2.copyMakeBorder(imagen, a, a, b, b, cv2.BORDER_REPLICATE)\n",
    "    aux = 0\n",
    "    for i in range(a, filas+a):\n",
    "        for j in range(b, columnas+b):\n",
    "            imagen2[:, aux] = imagen_amp[i-a:i+a+1, j-b:j+b+1].flatten()\n",
    "            aux += 1\n",
    "    return imagen2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_2(image, N, R, M=1):\n",
    "\n",
    "    maskX = np.array([[0, 0, 0], [-1, 0, 1], [0, 0, 0]])\n",
    "    maskY = np.array([[0, -1, 0], [0, 0, 0], [0, 1, 0]])\n",
    "\n",
    "    dx = convolve(image, maskX, mode='same')\n",
    "    dy = convolve(image, maskY, mode='same')\n",
    "\n",
    "    magnitudes = np.uint8(np.sqrt(np.square(dx) + np.square(dy)))\n",
    "\n",
    "    PhiRad = np.arctan2(dy, dx)\n",
    "    phi = np.uint8(np.rad2deg(PhiRad))\n",
    "\n",
    "    orientaciones = np.abs(phi)//20\n",
    "    celdasMag = crearCeldas(magnitudes, N)\n",
    "\n",
    "    celdasMask = np.zeros(\n",
    "        (9, celdasMag.shape[0], celdasMag.shape[1], celdasMag.shape[2]))\n",
    "    for i in range(celdasMask.shape[0]):\n",
    "        celdasMask[i] = crearCeldas(orientaciones == i, N)\n",
    "\n",
    "    histograms = np.zeros((len(celdasMag), 9))\n",
    "\n",
    "    histograms = np.sum(celdasMask * celdasMag[:], axis=(2, 3)).T\n",
    "\n",
    "    histograms_normalized = normalize(histograms, axis=1)\n",
    "\n",
    "    vector = histograms_normalized.flatten()\n",
    "\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n"
     ]
    }
   ],
   "source": [
    "# Cargamos la imagen\n",
    "N = 16\n",
    "R = 3\n",
    "# Convertimos la imagen a escala de grises\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "result = feature_extraction_2(image, N, R)\n",
    "\n",
    "print(len(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  cat_dog_500\n",
      "Procesamos las imágenes de entrenamiento\n",
      "Procesando label:  cat\n",
      " Procesando Xtrain ... (100 %)\n",
      "Procesando label:  dog\n",
      " Procesando Xtrain ... (100 %)\n",
      "Procesamos las imágenes de prueba\n",
      "Procesando label:  cat\n",
      " Procesando Xtest ... (100 %)Procesando label:  dog\n",
      " Procesando Xtest ... (100 %)"
     ]
    }
   ],
   "source": [
    "datasets = [\"cat_dog_500\"]\n",
    "\n",
    "N = 16\n",
    "R = 3\n",
    "\n",
    "HEIGHT = 432\n",
    "WIDTH = 432\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(\"dataset: \", dataset)\n",
    "    # Iniciamos el contador de tiempo\n",
    "    startTimer = time.perf_counter()\n",
    "\n",
    "    # Definimos el directorio de entrenamiento y prueba\n",
    "    train_dir = dataset+\"/\"+\"train\"\n",
    "    test_dir = dataset+\"/\"+\"test\"\n",
    "\n",
    "    # Inicializamos los arrays de datos de entrenamiento y prueba\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    print(\"Procesamos las imágenes de entrenamiento\")\n",
    "    # Procesamos las imágenes de entrenamiento\n",
    "    for label in os.listdir(train_dir):\n",
    "        label_dir = os.path.join(train_dir, label)\n",
    "        print(\"Procesando label: \", label)\n",
    "        for count, image_filename in enumerate(os.listdir(label_dir)):\n",
    "            image_path = os.path.join(label_dir, image_filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            resized_image = cv2.resize(\n",
    "                image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            features = feature_extraction_2(resized_image, N, R)\n",
    "            X_train.append(features)\n",
    "            y_train.append(label)\n",
    "\n",
    "            progress = 100 * (count + 1) / len(os.listdir(label_dir))\n",
    "            sys.stdout.write(\n",
    "                \"\\r Procesando Xtrain ... (\" + str(int(progress)) + \" %)\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Procesamos las imágenes de prueba\")\n",
    "    # Procesamos las imágenes de prueba\n",
    "    for label in os.listdir(test_dir):\n",
    "        label_dir = os.path.join(test_dir, label)\n",
    "        print(\"Procesando label: \", label)\n",
    "        for count, image_filename in enumerate(os.listdir(label_dir)):\n",
    "            image_path = os.path.join(label_dir, image_filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            resized_image = cv2.resize(\n",
    "                image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "            features = feature_extraction_2(resized_image, N, R)\n",
    "            X_test.append(features)\n",
    "            y_test.append(label)\n",
    "\n",
    "            progress = 100 * (count + 1) / len(os.listdir(label_dir))\n",
    "            sys.stdout.write(\n",
    "                \"\\r Procesando Xtest ... (\" + str(int(progress)) + \" %)\")\n",
    "\n",
    "    # Convertimos los datos de entrenamiento y prueba a arrays de NumPy\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 90.00%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=C_best, gamma=gamma_best)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Realizamos predicciones con el clasificador entrenado\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculamos el porcentaje de acierto\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Precisión: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros C: 5.0, gamma: 0.01\n",
      "Precisión: 92.50%\n",
      "Tiempo transcurrido: 2 minutos 24.65 segundos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "C_values = [0.1, 1.0, 5.0, 7.5, 10.0]\n",
    "gamma_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Genera el diccionario param_grid con los valores indicados\n",
    "param_grid = {'C': C_values, 'gamma': gamma_values}\n",
    "\n",
    "# Genera el objeto ShuffleSplit para generar un único particionado fijo, con 20% de datos de validación y\n",
    "# random_state = 0\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.20, random_state=0)\n",
    "\n",
    "# Haz la llamada a la función GridSearchCV con un clasificador SVC y el diccionario de parámetros definido\n",
    "# Para acelerar algo el entrenamiento, emplea también el parámetro n_jobs=-1, que hará que se aproveche mejor el\n",
    "# procesador de tu equipo.\n",
    "clasificadores = GridSearchCV(SVC(), param_grid, n_jobs=-1, cv=rs)\n",
    "\n",
    "# Entrena el modelo interno de GridSearchCV, y después obten los mejores valores de C y gamma en C_best y gamma_best\n",
    "clasificadores.fit(X_train, y_train)\n",
    "\n",
    "C_best = clasificadores.best_params_[\"C\"]\n",
    "gamma_best = clasificadores.best_params_[\"gamma\"]\n",
    "\n",
    "print(\"Mejores parámetros C: {}, gamma: {}\".format(C_best, gamma_best))\n",
    "\n",
    "# Crea y entrena un modelo SVC con C_best y gamma_best sobre los datos de train originales (X e y)\n",
    "clf = SVC(C=C_best, gamma=gamma_best)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predicciones con el clasificador entrenado\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculamos el porcentaje de acierto\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Precisión: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Detenemos el contador de tiempo\n",
    "endTimer = time.perf_counter()\n",
    "\n",
    "# Calculamos el tiempo transcurrido\n",
    "elapsed = endTimer - startTimer\n",
    "# Obtenemos el tiempo transcurrido en minutos y segundos\n",
    "minutes, seconds = divmod(elapsed, 60)\n",
    "\n",
    "# Mostramos el tiempo transcurrido en minutos y segundos\n",
    "print(f\"Tiempo transcurrido: {minutes:.0f} minutos {seconds:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros C: 1.0\n",
      "Precisión: 82.50%\n",
      "Tiempo transcurrido: 0 minutos 37.99 segundos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "C_values = [0.1, 1.0, 5.0, 10.0]\n",
    "#gamma_values = [0,0.001,]\n",
    "\n",
    "# Genera el diccionario param_grid con los valores indicados\n",
    "param_grid = {'C': C_values}\n",
    "\n",
    "# Genera el objeto ShuffleSplit para generar un único particionado fijo, con 20% de datos de validación y\n",
    "# random_state = 0\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.20, random_state=0)\n",
    "\n",
    "# Haz la llamada a la función GridSearchCV con un clasificador SVC y el diccionario de parámetros definido\n",
    "# Para acelerar algo el entrenamiento, emplea también el parámetro n_jobs=-1, que hará que se aproveche mejor el\n",
    "# procesador de tu equipo.\n",
    "clasificadores = GridSearchCV(SVC(), param_grid, n_jobs=-1, cv=rs)\n",
    "\n",
    "# Entrena el modelo interno de GridSearchCV, y después obten los mejores valores de C y gamma en C_best y gamma_best\n",
    "clasificadores.fit(X_train, y_train)\n",
    "\n",
    "C_best = clasificadores.best_params_[\"C\"]\n",
    "#gamma_best = clasificadores.best_params_[\"gamma\"]\n",
    "\n",
    "print(\"Mejores parámetros C: {}\".format(C_best))\n",
    "\n",
    "# Crea y entrena un modelo SVC con C_best y gamma_best sobre los datos de train originales (X e y)\n",
    "clf = SVC(C=C_best, gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predicciones con el clasificador entrenado\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculamos el porcentaje de acierto\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Precisión: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Detenemos el contador de tiempo\n",
    "endTimer = time.perf_counter()\n",
    "\n",
    "# Calculamos el tiempo transcurrido\n",
    "elapsed = endTimer - startTimer\n",
    "# Obtenemos el tiempo transcurrido en minutos y segundos\n",
    "minutes, seconds = divmod(elapsed, 60)\n",
    "\n",
    "# Mostramos el tiempo transcurrido en minutos y segundos\n",
    "print(f\"Tiempo transcurrido: {minutes:.0f} minutos {seconds:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  cat_dog_100\n",
      "Procesamos las imágenes de entrenamiento\n",
      "Procesando label:  cat\n",
      " Procesando Xtrain ... (51 %)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14388\\1038114329.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extraction_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14388\\5988810.py\u001b[0m in \u001b[0;36mfeature_extraction_2\u001b[1;34m(image, N, R, M)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mPhiRad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marctan2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdy\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mphi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrad2deg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPhiRad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0morientaciones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = [\"cat_dog_100\"]\n",
    "\n",
    "N = 16\n",
    "R = 3\n",
    "\n",
    "HEIGHT = 432\n",
    "WIDTH = 432\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(\"dataset: \", dataset)\n",
    "    # Iniciamos el contador de tiempo\n",
    "    startTimer = time.perf_counter()\n",
    "\n",
    "    # Definimos el directorio de entrenamiento y prueba\n",
    "    train_dir = dataset+\"/\"+\"train\"\n",
    "    test_dir = dataset+\"/\"+\"test\"\n",
    "\n",
    "    # Inicializamos los arrays de datos de entrenamiento y prueba\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    print(\"Procesamos las imágenes de entrenamiento\")\n",
    "    # Procesamos las imágenes de entrenamiento\n",
    "    for label in os.listdir(train_dir):\n",
    "        label_dir = os.path.join(train_dir, label)\n",
    "        print(\"Procesando label: \", label)\n",
    "        for count, image_filename in enumerate(os.listdir(label_dir)):\n",
    "            image_path = os.path.join(label_dir, image_filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            resized_image = cv2.resize(\n",
    "                image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            features = feature_extraction_2(resized_image, N, R)\n",
    "            X_train.append(features)\n",
    "            y_train.append(label)\n",
    "\n",
    "            progress = 100 * (count + 1) / len(os.listdir(label_dir))\n",
    "            sys.stdout.write(\n",
    "                \"\\r Procesando Xtrain ... (\" + str(int(progress)) + \" %)\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Procesamos las imágenes de prueba\")\n",
    "    # Procesamos las imágenes de prueba\n",
    "    for label in os.listdir(test_dir):\n",
    "        label_dir = os.path.join(test_dir, label)\n",
    "        print(\"Procesando label: \", label)\n",
    "        for count, image_filename in enumerate(os.listdir(label_dir)):\n",
    "            image_path = os.path.join(label_dir, image_filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            resized_image = cv2.resize(\n",
    "                image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "            features = feature_extraction_2(resized_image, N, R)\n",
    "            X_test.append(features)\n",
    "            y_test.append(label)\n",
    "\n",
    "            progress = 100 * (count + 1) / len(os.listdir(label_dir))\n",
    "            sys.stdout.write(\n",
    "                \"\\r Procesando Xtest ... (\" + str(int(progress)) + \" %)\")\n",
    "\n",
    "    # Convertimos los datos de entrenamiento y prueba a arrays de NumPy\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb8fc1c56b9f1b0b3180fd07060a5da82fc27bc3d2493c5fd6601f54d16efe45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
