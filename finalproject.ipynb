{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(N):\n",
    "  # Calculamos el histograma de los píxeles del bloque\n",
    "  histogram = cv2.calcHist([N], [0], None, [256], [0, 256])\n",
    "\n",
    "  # Devolvemos el histograma como un vector\n",
    "  return histogram.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_to_col(imagen, m, n):\n",
    "    filas, columnas = imagen.shape\n",
    "    a = m//2\n",
    "    b = n//2\n",
    "    imagen2 = np.zeros((m*n, filas*columnas))\n",
    "    imagen_amp = cv2.copyMakeBorder(imagen, a, a, b, b, cv2.BORDER_REPLICATE)\n",
    "    aux = 0\n",
    "    for i in range(a, filas+a):\n",
    "        for j in range(b, columnas+b):\n",
    "            imagen2[:, aux] = imagen_amp[i-a:i+a+1, j-b:j+b+1].flatten()\n",
    "            aux += 1\n",
    "    return imagen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction2(image, N , R):\n",
    "  # Obtenemos las dimensiones de la imagen\n",
    "  height, width = image.shape[:2]  \n",
    "\n",
    "  print(\"IMAGEN NxM: \",height, \"x\",width )\n",
    " \n",
    " \n",
    "\n",
    "  # Calculamos el número de bloques en filas y columnas\n",
    "  num_blocks_rows = height // N\n",
    "  num_blocks_cols = width // N\n",
    "\n",
    "  # Dividimos la imagen en bloques de 16 filas\n",
    "  blocks = np.vsplit(image, num_blocks_rows)\n",
    "\n",
    "  # Creamos una lista para guardar todas las celdas\n",
    "  celdas = []\n",
    "\n",
    "  # Iteramos sobre los bloques\n",
    "  for i, block in enumerate(blocks):\n",
    "    # Dividimos cada bloque en bloques de 16 columnas\n",
    "    cells = np.hsplit(block, num_blocks_cols)\n",
    "\n",
    "    # Iteramos sobre las celdas\n",
    "    for j, cell in enumerate(cells):\n",
    "      # Añadimos cada celda a la lista\n",
    "      celdas.append(cell)\n",
    "  \n",
    "  celdas = np.array(celdas)\n",
    "  print(\"TENEMOS: \",len(celdas), \" celdas\")\n",
    "  histograms = np.zeros((len(celdas) , N*N))\n",
    "\n",
    "  for i, celda in enumerate(celdas):    \n",
    "    vecinos = im_to_col(celda,R,R).T\n",
    "\n",
    "    result = np.zeros(N*N, np.uint8)\n",
    "\n",
    "    for j, v in enumerate(vecinos):\n",
    "      v = v.reshape(R,R)  \n",
    "\n",
    "      center_pixel = v[1,1]   \n",
    "      # Inicializamos el valor binario a 0\n",
    "      binary = ''   \n",
    "\n",
    "      for x in range(R):\n",
    "        for y in range(R):  \n",
    "\n",
    "          # Saltamos el píxel central          \n",
    "          if x == 1 and y == 1:\n",
    "            continue             \n",
    "\n",
    "          # Actualizamos el valor binario en función del vecino\n",
    "          if v[x, y] < center_pixel:\n",
    "            binary += '0'\n",
    "          else:\n",
    "            binary += '1'\n",
    "\n",
    "      # Modificamos el valor del píxel central por el del número binario obtenido\n",
    "      result[j] = int(binary,2)\n",
    "\n",
    "    # Calculamos el histograma del bloque\n",
    "    histograms[i] = get_histogram(result)          \n",
    "    \n",
    "\n",
    "  return histograms.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(image, N , R):\n",
    "  # Obtenemos las dimensiones de la imagen\n",
    "  height, width = image.shape[:2]  \n",
    "\n",
    "  #print(\"IMAGEN NxM: \",height, \"x\",width )\n",
    " \n",
    "  # Calculamos el número de bloques en filas y columnas\n",
    "  num_blocks_rows = height // N\n",
    "  num_blocks_cols = width // N\n",
    "\n",
    "  # Dividimos la imagen en bloques de N filas\n",
    "  blocks = np.vsplit(image, num_blocks_rows)\n",
    "\n",
    "  # Creamos una lista para guardar todas las celdas\n",
    "  celdas = []\n",
    "\n",
    "  # Iteramos sobre los bloques\n",
    "  for i, block in enumerate(blocks):\n",
    "    # Dividimos cada bloque en bloques de N columnas\n",
    "    cells = np.hsplit(block, num_blocks_cols)\n",
    "\n",
    "    # Iteramos sobre las celdas\n",
    "    for j, cell in enumerate(cells):\n",
    "      # Añadimos cada celda a la lista\n",
    "      celdas.append(cell)\n",
    "  \n",
    "  celdas = np.array(celdas)\n",
    "  #print(\"TENEMOS: \",len(celdas), \" celdas\")\n",
    "  histograms = np.zeros((len(celdas) , N*N))\n",
    "\n",
    "  for i, celda in enumerate(celdas):    \n",
    "    vecinos = im_to_col(celda,R,R).T\n",
    "    # Inicializamos el array de resultados para todos los vecinos\n",
    "    result = np.zeros(vecinos.shape[0], np.uint8)\n",
    "    # Iteramos sobre cada vecino\n",
    "    for j, v in enumerate(vecinos):\n",
    "      v = v.reshape(R,R)  \n",
    "      # Obtenemos el valor del píxel central\n",
    "      center_pixel = v[1,1]\n",
    "      # Inicializamos el valor binario a 0\n",
    "      binary = ''   \n",
    "      # Iteramos sobre los vecinos de la celda, excluyendo el píxel central\n",
    "      for x in range(R):\n",
    "        for y in range(R):  \n",
    "          if x == 1 and y == 1:\n",
    "            continue             \n",
    "          if v[x, y] < center_pixel:\n",
    "            binary += '0'\n",
    "          else:\n",
    "            binary += '1'\n",
    "      # Modificamos el valor del píxel central por el del número binario obtenido\n",
    "      result[j] = int(binary,2)\n",
    "\n",
    "    # Calculamos el histograma del bloque\n",
    "    histograms[i] = get_histogram(result)          \n",
    "    \n",
    "\n",
    "  return histograms.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGEN NxM:  128 x 128\n",
      "TENEMOS:  64  celdas\n",
      "16384\n"
     ]
    }
   ],
   "source": [
    "# Cargamos la imagen\n",
    "N = 16\n",
    "R = 3\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)# Convertimos la imagen a escala de grises\n",
    "\n",
    "result = feature_extraction2(image, N ,R)\n",
    "\n",
    "print(len(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"cat_dog_100\" , \"cat_dog_500\"]\n",
    "\n",
    "HEIGHT = 384\n",
    "WIDTH = 528\n",
    "\n",
    "for dataset in datasets:\n",
    "  print(\"dataset: \",dataset)\n",
    "  # Iniciamos el contador de tiempo\n",
    "  startTimer = time.perf_counter()\n",
    "\n",
    "  # Definimos el directorio de entrenamiento y prueba\n",
    "  train_dir = dataset+\"/\"+\"train\"\n",
    "  test_dir = dataset+\"/\"+\"test\"\n",
    "\n",
    "  # Inicializamos los arrays de datos de entrenamiento y prueba\n",
    "  X_train = []\n",
    "  y_train = []\n",
    "  X_test = []\n",
    "  y_test = []\n",
    "\n",
    "  print(\"Procesamos las imágenes de entrenamiento\")\n",
    "  # Procesamos las imágenes de entrenamiento\n",
    "  for label in os.listdir(train_dir):\n",
    "    label_dir = os.path.join(train_dir, label)\n",
    "    print(\"Procesando label: \",label)\n",
    "    for count , image_filename in enumerate(os.listdir(label_dir)):\n",
    "      image_path = os.path.join(label_dir, image_filename)\n",
    "      image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "      resized_image = cv2.resize(image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "      features = feature_extraction(resized_image, N, R)\n",
    "      X_train.append(features)\n",
    "      y_train.append(label)\n",
    "\n",
    "      progress = 100 * (count + 1) / len(os.listdir(label_dir))\n",
    "      sys.stdout.write(\"\\r Procesando Xtrain ... (\" + str(int(progress)) + \" %)\")\n",
    "    print(\"\")\n",
    "\n",
    "  \n",
    "\n",
    "  print(\"Procesamos las imágenes de prueba\")\n",
    "  # Procesamos las imágenes de prueba\n",
    "  for label in os.listdir(test_dir):\n",
    "    label_dir = os.path.join(test_dir, label)\n",
    "    print(\"Procesando label: \",label)\n",
    "    for count , image_filename in enumerate(os.listdir(label_dir)):\n",
    "      image_path = os.path.join(label_dir, image_filename)\n",
    "      image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "      resized_image = cv2.resize(image, (HEIGHT, WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "      features = feature_extraction(resized_image, N, R)\n",
    "      X_test.append(features)\n",
    "      y_test.append(label)\n",
    "\n",
    "      progress = 100 * (count + 1) / len(os.listdir(label_dir))\n",
    "      sys.stdout.write(\"\\r Procesando Xtest ... (\" + str(int(progress)) + \" %)\")\n",
    "\n",
    "  # Convertimos los datos de entrenamiento y prueba a arrays de NumPy\n",
    "  X_train = np.array(X_train,np.uint8)\n",
    "  y_train = np.array(y_train)\n",
    "  X_test = np.array(X_test,np.uint8)\n",
    "  y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "  # Guardamos los datos de entrenamiento y prueba en ficheros\n",
    "  np.savetxt(\"datasets/\"+dataset+\"_X_train.txt\", X_train,fmt=\"%u\")\n",
    "  np.savetxt(\"datasets/\"+dataset+\"_y_train.txt\", y_train, fmt=\"%s\")\n",
    "  np.savetxt(\"datasets/\"+dataset+\"_X_test.txt\", X_test,fmt=\"%u\")\n",
    "  np.savetxt(\"datasets/\"+dataset+\"_y_test.txt\", y_test, fmt=\"%s\")\n",
    "\n",
    "\n",
    "  # Detenemos el contador de tiempo\n",
    "  endTimer = time.perf_counter()\n",
    "\n",
    "  # Calculamos el tiempo transcurrido\n",
    "  elapsed = endTimer - startTimer\n",
    "  # Obtenemos el tiempo transcurrido en minutos y segundos\n",
    "  minutes, seconds = divmod(elapsed, 60)\n",
    "\n",
    "  # Mostramos el tiempo transcurrido en minutos y segundos\n",
    "  print(f\"Tiempo transcurrido: {minutes:.0f} minutos {seconds:.2f} segundos\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  cat_dog_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2012m\\AppData\\Local\\Temp\\ipykernel_11700\\4182968165.py:8: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  X_train = np.loadtxt(\"datasets/\"+dataset+\"_X_train.txt\" ,dtype=np.uint8)\n",
      "C:\\Users\\2012m\\AppData\\Local\\Temp\\ipykernel_11700\\4182968165.py:10: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  X_test = np.loadtxt(\"datasets/\"+dataset+\"_X_test.txt\" ,dtype=np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 95.00%\n",
      "dataset:  cat_dog_500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2012m\\AppData\\Local\\Temp\\ipykernel_11700\\4182968165.py:8: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  X_train = np.loadtxt(\"datasets/\"+dataset+\"_X_train.txt\" ,dtype=np.uint8)\n",
      "C:\\Users\\2012m\\AppData\\Local\\Temp\\ipykernel_11700\\4182968165.py:10: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  X_test = np.loadtxt(\"datasets/\"+dataset+\"_X_test.txt\" ,dtype=np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 94.50%\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"cat_dog_100\" , \"cat_dog_500\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "  print(\"dataset: \",dataset) \n",
    "\n",
    "\n",
    "  # Cargamos los datos de entrenamiento y prueba desde los ficheros\n",
    "  X_train = np.loadtxt(\"datasets/\"+dataset+\"_X_train.txt\" ,dtype=np.uint8)\n",
    "  y_train = np.loadtxt(\"datasets/\"+dataset+\"_y_train.txt\",dtype=str)\n",
    "  X_test = np.loadtxt(\"datasets/\"+dataset+\"_X_test.txt\" ,dtype=np.uint8)\n",
    "  y_test = np.loadtxt(\"datasets/\"+dataset+\"_y_test.txt\", dtype=str)\n",
    "  \n",
    "  \n",
    "\n",
    "  # Creamos un clasificador SVM\n",
    "  clf = SVC(gamma='auto')\n",
    "\n",
    "  # Entrenamos el clasificador con los datos de entrenamiento\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "  # Realizamos predicciones con el clasificador entrenado\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  # Calculamos el porcentaje de acierto\n",
    "  accuracy = np.mean(y_pred == y_test)\n",
    "  print(\"Precisión: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
